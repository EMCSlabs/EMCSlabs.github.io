---
layout: post
title: word2vec
description: "word2vec"
headline: "word2vec"
categories: MACHINELEARNING
tags: 
  - Machine Learning
  - NLP
comments: false
mathjax: true
featured: true
published: true
---

## word2vec

### 개념
- word2vec은 one hot coded된 단어 representation을 기반으로
- t 시점의 단어와 t-2, t-1, t+1, t+2 시점의 단어 사이의 mapping (e.g. you --> I love so much) 을 ANN으로 훈련하여 얻는 각 단어의 hidden 값.

### Input - Hidden - Output
- 이때 훈련에 쓰이는 input과 output의 dimension은 1xV (V: vocabulary size) --> 1x4V. (e.g. I love \<you\> so much)
- Hidden 층은 단어 하나를 표기하기 위한 dimension인 V 보다 훨씬 낮은 차원을 사용할 수 있다. (보통 300 정도 설정)
- 결국 300차원 정도의 vector space에서 의미적, 통사적으로 유사한 단어들이 군집을 이룬다.

<p align="right"> Hosung Nam <p>
