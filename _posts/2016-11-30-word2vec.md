---
layout: post
title: word2vec
description: "word2vec"
headline: "word2vec"
categories: personal
tags: 
  - Machine Learning
  - NLP
comments: false
mathjax: true
featured: true
published: true
---

word2vec은 one hot coded된 단어 representation을 기반으로 t의 단어와 t-2, t-1, t+1, t+2의 단어 사이의 mapping (e.g. you --> I love so much) 을 ANN으로 train 완료 후, 어떤 단어에 대한 hidden을 word2vec으로 사용함. 이때 훈련에 쓰이는 input과 output의 dimension은 1xV (V: voca size) --> 1x4V. hidden 층은 단어 하나를 표기하기 위한 dimension V보다 훨씬 낮은 차원을 사용할 수 있다. (보통 300 정도 설정). 300차원의 vector space에서 의미적으로 통사적으로 유사한 단어들이 군집을 이룬다.
